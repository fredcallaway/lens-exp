"""Tools for running language experiments with SRNs"""

from glob import glob
import logging
import time
import subprocess
import cPickle as pickle
from copy import deepcopy
import os
import psutil
import sys

import create_files
from lens import write_lens_files
from experiment import evaluate_experiment
from segmentation import test_segmentation

LENS_LOCATION = '/Applications/LensOSX.app/Contents/MacOS/LensOSX'
logging.basicConfig(level=logging.WARNING)


class Network(object):
    """A simple recurrent network to be used in experimental modeling

    Attributes:
        seed (int): seed used for random initial net weights.
        hidden (int): number of hidden units.
        rate (float): learning rate.
        momentum (float): momentum.
        ticks (int): number of examples that backpropogation goes back.
        num_train (int): number of training examples.
        incoding (dict): maps phonemes to input layer network representations.
        outcoding (dict): maps phonemes to outupt layer network representations.
        time (str): last time the network was modified.
        segmentation_results (dict): network performance on the segmentation task.
            Generated by `self.train_network`.
            Keys:
                boundary_precision (float): boundary detection precision
                boundary_recall (float): boundary detection recall
                boundary_F (float): boundary detection F score
                word_precision (float): word detection precision
                word_recall (float): word detection recall
                word_F (float): word detection F score
        experiment_results (dict): network performance on the ALL experiment.
            Generated by `self.run_experiment`.
            Keys:
                exp(A|B)_accuracy (float): average accuracy of choices for the
                    (contoid|vocoid) language across 1000 trials
                exp(A|B)_std (float): standard deviation of accuracy
                exp(A|B)_errors (tuple list): network errors for each trial on
                    the (contoid|vocoid) language. Note that these are errors in the
                    neural network sense, not errors in the experiment
                exp(A|B)_rts (float list): reaction time for each trial
                    currently, the inverse of percentage difference between errors

        """
    def __init__(self, lang, seed=0, distributed=False, hidden=80, rate=0.1,
                 momentum=0.95, ticks=1, rand_range=0.25, num_train=696692,):
        super(Network, self).__init__()

        self.lang = lang
        self.seed = seed
        self.hidden = hidden
        self.rate = rate
        self.momentum = momentum
        self.ticks = ticks
        self.rand_range = rand_range
        self.num_train = num_train
        self.distributed = distributed
        self.incoding = {}
        self.outcoding = {}
        self.time = time.strftime('%m/%d at %H:%M:%S')  # last time results were changed
        self._id = None

        self.segmentation_results = {}
        self.experiment_results = {}

        # these methods defines critical attributes, thus
        # they must be called upon initialization
        self._write_example_files()
        self._create_id()

        # load previously trained and tested network if possible
        try:
            net = pickle.load(open('nets/%s.p' % self._id))
            self.segmentation_results = net.segmentation_results
            self.experiment_results = net.experiment_results
            self.time = net.time
            logging.info('loading existing network results')
        except IOError:
            pickle.dump(self, open('nets/%s.p' % self._id, 'wb'))

    def __getattr__(self, attr):
        # treat keys of results dicts as attributes
        if attr.startswith('__') and attr.endswith('__'):
            # workaround for bugs with pickle and special methods
            return super(Network, self).__getattr__(attr)
        try:
            return self.segmentation_results[attr]
        except KeyError:
            try:
                return self.experiment_results[attr]
            except:
                raise AttributeError("'Network' object has no attribute '%s'" % attr)

    def train_network(self, retrain=True):
        """Trains the network and tests segmentation ability

        Updates self.segmentation_results with results"""
        logging.debug('executing train_network()')
        self._write_example_files()
        self._write_lens_files()
        if (not os.path.isfile('lens/weights/' + self._id + '.wt')  # already trained
            or retrain):
                self._run_lens('training')
        self._run_lens('testing')
        self.segmentation_results = test_segmentation(self.lang, 'break_average')

        self.time = time.strftime('%m/%d at %H:%M:%S')
        pickle.dump(self, open('nets/%s.p' % self._id, 'wb'))

    def run_experiment(self):
        """Runs the network on the ALL experiment

        Updates self.experiment_results with results"""
        logging.debug('executing run_experiment()')
        self._write_example_files()
        self._write_lens_files()
        lens_output = self._run_lens('experiment')
        self.experiment_results = evaluate_experiment(lens_output)

        self.time = time.strftime('%m/%d at %H:%M:%S')
        pickle.dump(self, open('nets/%s.p' % self._id, 'wb'))

    def _create_id(self):
        """Create id which uniquly identifies self"""
        logging.debug('executing _create_id()')
        distributed = 'd' if self.distributed else 'l'
        rate = str(self.rate)[2:]
        momentum = str(self.momentum)[2:]
        rand_range = str(self.rand_range)[2:]
        self._id = ('%s_%s_%s_%s_%s_%s_%s_%s_%s'
                    % (self.lang, distributed, self.seed, self.hidden, rate,
                       momentum, self.ticks, rand_range, self.num_train,))

    def _write_example_files(self):
        logging.debug('executing _write_example_files()')
        # note: num_train is updated to the actual number of
        # examples that are generated
        tmp = self.num_train
        self.num_train, self.incoding, self.outcoding = \
            create_files.write_example_files(self.lang, self.distributed, self.num_train)
        if self.num_train != tmp:
            logging.warning('num_train has been changed from'
                            '%s to %s' % (tmp, self.num_train))

    def _write_lens_files(self):
        logging.debug('executing _write_lens_files()')
        input_ = len(self.incoding)
        output = len(self.outcoding)
        write_lens_files(self._id, self.seed, input_, self.hidden,
                         output, self.num_train, self.rate,
                         self.momentum, self.ticks, self.rand_range)

    def _test_segmentation(self):
        logging.debug('executing test_segmentation()')
        self._run_lens('testing')
        self.segmentation_results = test_segmentation(self.lang, 'break_average')
        pickle.dump(self, open('nets/%s.p' % self._id, 'wb'))

    def _run_lens(self, in_file):
        try:
            # todo: pipe output to terminal and python
            logging.info("executing _run_lens('%s')" % in_file)
            out = subprocess.Popen([LENS_LOCATION, '-b', 'lens/%s.in' % in_file],
                                   stdout=subprocess.PIPE).communicate()[0]
            if not out[-8:] == 'success\n':
                raise RuntimeError('Error whil executing lens/%s.in' % in_file)
            out = out[:out.rindex('\n')]  # remove success message
            with open('%s-log.out' % in_file, 'w') as f:
                f.write(out)
            return out
        finally:
            # kill any remaining Lens processes
            for proc in psutil.process_iter():
                if proc.name() == 'LensOSX':
                    proc.kill()


def create_csv(file_name='net-log.csv', columns=None, rounding=3):
    """Creates a .csv file for all nets in nets/ with parameters and results"""
    import csv
    default_headers = ['time', 'lang', 'distributed', 'seed', 'word_F',
                       'expB_accuracy', 'expA_accuracy']

    all_headers = ['time', 'lang', 'distributed', 'seed', 'hidden', 'rate', 'momentum',
                   'ticks', 'rand_range', 'num_train', 'boundary_precision',
                   'boundary_recall', 'boundary_F', 'word_precision', 'word_recall',
                   'word_F', 'expA_accuracy', 'expB_accuracy', 'expA_reaction',
                   'expB_reaction', 'expA_std', 'expB_std', 'expA_rts', 'expB_rts',
                   'expA_errors', 'expB_errors']

    if columns is None:
        headers = default_headers
    elif columns == 'all':
        headers = all_headers
    else:
        headers = default_headers + columns
        headers.sort(key=lambda col: all_headers.index(col))

    # get the parameters and results for all networks in nets/
    rows = []
    for net_file in glob('nets/*.p'):
        net = pickle.load(open(net_file))
        entry = {}
        for attr in headers:
            try:
                entry[attr] = getattr(net, attr)
            except AttributeError:
                entry[attr] = None
        if rounding:
            for k, v in entry.items():
                try:
                    entry[k] = round(float(str(v)), rounding)
                except ValueError:
                    pass
                except TypeError:
                    pass

        rows.append(entry)
    rows = sorted(rows, key=lambda d: d['time'])

    with open(file_name, 'w+') as csv_file:
        writer = csv.DictWriter(csv_file, headers)
        writer.writeheader()
        writer.writerows(rows)


def run_nets(parameters, rerun=None):
    """Runs a series of nets"""
    if not isinstance(parameters, list):
        parameters = [parameters]
    print 'NOW RUNNING %s NETS' % len(parameters)
    for param in parameters:
        net = Network(**param)
        net.run(rerun=rerun)


def generate_permutations(parameters):
    """Returns all possible permutations of params in parameters

    parmeters must be a list of (str, list) tuples, where str is
    the key and list, a list of values"""

    def recurse(parameters, permutations):
        if not parameters:
            return permutations

        # return a copy of permutations with all possible values
        #   for param added to each permutation
        # this multiplies len(permutations) by len(values)
        param, values = parameters.pop(0)
        new_perms = []
        for v in values:
            perm_copy = deepcopy(permutations)
            for perm in perm_copy:
                perm[param] = v
            new_perms += perm_copy

        return recurse(parameters, new_perms)

    parameters.reverse()  # so that result is sorted by first parameter
    param, values = parameters.pop(0)
    permutations = [{param: val} for val in values]
    return recurse(parameters, permutations)


def custom_script(*args):
    """The script to be run when executing this file

    Takes command line arguments"""
    params = generate_permutations([('lang', ['danish', 'english']),
                                    ('seed', range(28)),
                                    ('num_train', [1])])
    run_nets(params)


def main(args):
    global LENS_LOCATION
    if not os.path.isfile(LENS_LOCATION):
        LENS_LOCATION = '/Users/fred/Applications/LensOSX.app/Contents/MacOS/LensOSX'

    if 'csv' in args:
        cols = args[args.index('csv') + 1:]
        if 'all' in cols:
            cols = 'all'
        create_csv(columns=cols)

    else:
        custom_script(*args)


if __name__ == '__main__':
    main(sys.argv[1:])
